{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Step 1: Data Preparation\n",
    "\n",
    "Since data preparation is a crucial step in the data science and machine learning workflow, we start with having a look at our data, its structure and flaws. Our primary goals in this phase include, however we might not follow the order listed below:\n",
    "\n",
    "**1. Cleaning Data:**\n",
    "    - Removing or correcting errors and inconsistencies in the data.\n",
    "\n",
    "**2. Transforming Data:**\n",
    "    - Standardizing or normalizing numerical features to ensure consistency and comparability.\n",
    "    - Encoding categorical variables into numerical representations that can be used by machine learning algorithms.\n",
    "    - Creating new features or aggregating existing ones to extract more meaningful information.\n",
    "    \n",
    "**3. Handling Missing Values:**\n",
    "    - Choosing appropriate strategies for handling missing data, such as mean imputation, median imputation, or more advanced methods like regression imputation.\n",
    "    \n",
    "**4. Dealing with Outliers (We might decide to postpone this step to a later point.):**\n",
    "    - Identifying and addressing outliers that can significantly impact the analysis or model performance.\n",
    "    \n",
    "**5. Feature Engineering ((We might decide to postpone this step to a later point.)**:\n",
    "    - Selecting, transforming or creating new features to enhance the performance of our ML models.\n",
    "    \n",
    "**6. Data Formatting:**\n",
    "    - Ensuring that the data is in the right format for the chosen analysis and modeling techniques."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the next steps, we import the necessary packages and load our datasets. We first start with the charging sessiong dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T16:57:07.111294Z",
     "start_time": "2023-12-05T16:57:06.807026Z"
    }
   },
   "outputs": [],
   "source": [
    "# import all necessary packages\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T16:57:07.675497Z",
     "start_time": "2023-12-05T16:57:06.921242Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0                        id             connectionTime  \\\n0           0  5e23b149f9af8b5fe4b973cf  2020-01-02 13:08:54+00:00   \n1           1  5e23b149f9af8b5fe4b973d0  2020-01-02 13:36:50+00:00   \n2           2  5e23b149f9af8b5fe4b973d1  2020-01-02 13:56:35+00:00   \n3           3  5e23b149f9af8b5fe4b973d2  2020-01-02 13:59:58+00:00   \n4           4  5e23b149f9af8b5fe4b973d3  2020-01-02 14:00:01+00:00   \n\n              disconnectTime           doneChargingTime  kWhDelivered  \\\n0  2020-01-02 19:11:15+00:00  2020-01-02 17:31:35+00:00        25.016   \n1  2020-01-02 22:38:21+00:00  2020-01-02 20:18:05+00:00        33.097   \n2  2020-01-03 00:39:22+00:00  2020-01-02 16:35:06+00:00         6.521   \n3  2020-01-02 16:38:39+00:00  2020-01-02 15:18:45+00:00         2.355   \n4  2020-01-02 22:08:40+00:00  2020-01-02 18:17:30+00:00        13.375   \n\n                                sessionID  siteID  spaceID    stationID  \\\n0  1_1_179_810_2020-01-02 13:08:53.870034       1  AG-3F30  1-1-179-810   \n1  1_1_193_825_2020-01-02 13:36:49.599853       1  AG-1F01  1-1-193-825   \n2  1_1_193_829_2020-01-02 13:56:35.214993       1  AG-1F03  1-1-193-829   \n3  1_1_193_820_2020-01-02 13:59:58.309319       1  AG-1F04  1-1-193-820   \n4  1_1_193_819_2020-01-02 14:00:00.779967       1  AG-1F06  1-1-193-819   \n\n              timezone  userID  \\\n0  America/Los_Angeles   194.0   \n1  America/Los_Angeles  4275.0   \n2  America/Los_Angeles   344.0   \n3  America/Los_Angeles  1117.0   \n4  America/Los_Angeles   334.0   \n\n                                          userInputs  \n0  [{'WhPerMile': 250, 'kWhRequested': 25.0, 'mil...  \n1  [{'WhPerMile': 280, 'kWhRequested': 70.0, 'mil...  \n2  [{'WhPerMile': 400, 'kWhRequested': 8.0, 'mile...  \n3  [{'WhPerMile': 400, 'kWhRequested': 8.0, 'mile...  \n4  [{'WhPerMile': 400, 'kWhRequested': 16.0, 'mil...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>connectionTime</th>\n      <th>disconnectTime</th>\n      <th>doneChargingTime</th>\n      <th>kWhDelivered</th>\n      <th>sessionID</th>\n      <th>siteID</th>\n      <th>spaceID</th>\n      <th>stationID</th>\n      <th>timezone</th>\n      <th>userID</th>\n      <th>userInputs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>5e23b149f9af8b5fe4b973cf</td>\n      <td>2020-01-02 13:08:54+00:00</td>\n      <td>2020-01-02 19:11:15+00:00</td>\n      <td>2020-01-02 17:31:35+00:00</td>\n      <td>25.016</td>\n      <td>1_1_179_810_2020-01-02 13:08:53.870034</td>\n      <td>1</td>\n      <td>AG-3F30</td>\n      <td>1-1-179-810</td>\n      <td>America/Los_Angeles</td>\n      <td>194.0</td>\n      <td>[{'WhPerMile': 250, 'kWhRequested': 25.0, 'mil...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>5e23b149f9af8b5fe4b973d0</td>\n      <td>2020-01-02 13:36:50+00:00</td>\n      <td>2020-01-02 22:38:21+00:00</td>\n      <td>2020-01-02 20:18:05+00:00</td>\n      <td>33.097</td>\n      <td>1_1_193_825_2020-01-02 13:36:49.599853</td>\n      <td>1</td>\n      <td>AG-1F01</td>\n      <td>1-1-193-825</td>\n      <td>America/Los_Angeles</td>\n      <td>4275.0</td>\n      <td>[{'WhPerMile': 280, 'kWhRequested': 70.0, 'mil...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5e23b149f9af8b5fe4b973d1</td>\n      <td>2020-01-02 13:56:35+00:00</td>\n      <td>2020-01-03 00:39:22+00:00</td>\n      <td>2020-01-02 16:35:06+00:00</td>\n      <td>6.521</td>\n      <td>1_1_193_829_2020-01-02 13:56:35.214993</td>\n      <td>1</td>\n      <td>AG-1F03</td>\n      <td>1-1-193-829</td>\n      <td>America/Los_Angeles</td>\n      <td>344.0</td>\n      <td>[{'WhPerMile': 400, 'kWhRequested': 8.0, 'mile...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>5e23b149f9af8b5fe4b973d2</td>\n      <td>2020-01-02 13:59:58+00:00</td>\n      <td>2020-01-02 16:38:39+00:00</td>\n      <td>2020-01-02 15:18:45+00:00</td>\n      <td>2.355</td>\n      <td>1_1_193_820_2020-01-02 13:59:58.309319</td>\n      <td>1</td>\n      <td>AG-1F04</td>\n      <td>1-1-193-820</td>\n      <td>America/Los_Angeles</td>\n      <td>1117.0</td>\n      <td>[{'WhPerMile': 400, 'kWhRequested': 8.0, 'mile...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>5e23b149f9af8b5fe4b973d3</td>\n      <td>2020-01-02 14:00:01+00:00</td>\n      <td>2020-01-02 22:08:40+00:00</td>\n      <td>2020-01-02 18:17:30+00:00</td>\n      <td>13.375</td>\n      <td>1_1_193_819_2020-01-02 14:00:00.779967</td>\n      <td>1</td>\n      <td>AG-1F06</td>\n      <td>1-1-193-819</td>\n      <td>America/Los_Angeles</td>\n      <td>334.0</td>\n      <td>[{'WhPerMile': 400, 'kWhRequested': 16.0, 'mil...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset\n",
    "dfCharging = pd.read_csv(\"Data/charging_sessions.csv\")\n",
    "dfCharging.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T16:57:07.814742Z",
     "start_time": "2023-12-05T16:57:07.669507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 66450 entries, 0 to 66449\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Unnamed: 0        66450 non-null  int64  \n",
      " 1   id                66450 non-null  object \n",
      " 2   connectionTime    66450 non-null  object \n",
      " 3   disconnectTime    66450 non-null  object \n",
      " 4   doneChargingTime  62362 non-null  object \n",
      " 5   kWhDelivered      66450 non-null  float64\n",
      " 6   sessionID         66450 non-null  object \n",
      " 7   siteID            66450 non-null  int64  \n",
      " 8   spaceID           66450 non-null  object \n",
      " 9   stationID         66450 non-null  object \n",
      " 10  timezone          66450 non-null  object \n",
      " 11  userID            49187 non-null  float64\n",
      " 12  userInputs        49187 non-null  object \n",
      "dtypes: float64(2), int64(2), object(9)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "dfCharging.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T16:57:07.925764Z",
     "start_time": "2023-12-05T16:57:07.729971Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove duplicate rows\n",
    "dfCharging = dfCharging.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0              0\n",
      "id                      0\n",
      "connectionTime          0\n",
      "disconnectTime          0\n",
      "doneChargingTime     4088\n",
      "kWhDelivered            0\n",
      "sessionID               0\n",
      "siteID                  0\n",
      "spaceID                 0\n",
      "stationID               0\n",
      "timezone                0\n",
      "userID              17263\n",
      "userInputs          17263\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(dfCharging.isnull().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T16:57:08.014646Z",
     "start_time": "2023-12-05T16:57:07.919692Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We note that the columns , 'userID', 'userInputs' and 'doneChargingTime' have a considerable number of missing values.\n",
    "\n",
    "First we check if the 'userID' matches the 'userInputs'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines with missing \"userID\" and \"userIputs\": 17263\n",
      "Percentage of compliance: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Check whether the lines with missing 'userInputs' also have missing 'userID'\n",
    "missing_userInputs = dfCharging['userInputs'].isnull()\n",
    "missing_userID = dfCharging['userID'].isnull()\n",
    "\n",
    "# Check that the missing values match\n",
    "matching_missing = dfCharging[missing_userInputs & missing_userID]\n",
    "\n",
    "# Output the number of matching lines\n",
    "print(f'Number of lines with missing \"userID\" and \"userIputs\": {len(matching_missing)}')\n",
    "\n",
    "# Calculate percentage of match\n",
    "total_missing_userInputs = len(dfCharging[missing_userInputs])\n",
    "if total_missing_userInputs > 0:\n",
    "    matching_percentage = (len(matching_missing) / total_missing_userInputs) * 100\n",
    "    print(f'Percentage of compliance: {matching_percentage:.2f}%')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T16:57:08.038849Z",
     "start_time": "2023-12-05T16:57:07.999215Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "data": {
      "text/plain": "0     194.0\n1    4275.0\n2     344.0\n3    1117.0\n4     334.0\nName: userID, dtype: float64"
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCharging['userID'].head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T16:57:08.040490Z",
     "start_time": "2023-12-05T16:57:08.024192Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [
    {
     "data": {
      "text/plain": "0    [{'WhPerMile': 250, 'kWhRequested': 25.0, 'mil...\n1    [{'WhPerMile': 280, 'kWhRequested': 70.0, 'mil...\n2    [{'WhPerMile': 400, 'kWhRequested': 8.0, 'mile...\n3    [{'WhPerMile': 400, 'kWhRequested': 8.0, 'mile...\n4    [{'WhPerMile': 400, 'kWhRequested': 16.0, 'mil...\nName: userInputs, dtype: object"
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCharging['userInputs'].head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T16:57:08.151149Z",
     "start_time": "2023-12-05T16:57:08.031577Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'WhPerMile': 250, 'kWhRequested': 25.0, 'milesRequested': 100, 'minutesAvailable': 463, 'modifiedAt': 'Thu, 02 Jan 2020 13:09:39 GMT', 'paymentRequired': True, 'requestedDeparture': 'Thu, 02 Jan 2020 20:51:54 GMT', 'userID': 194}]\n",
      "\n",
      "\n",
      "[{'WhPerMile': 280, 'kWhRequested': 70.0, 'milesRequested': 250, 'minutesAvailable': 595, 'modifiedAt': 'Thu, 02 Jan 2020 13:37:11 GMT', 'paymentRequired': True, 'requestedDeparture': 'Thu, 02 Jan 2020 23:31:50 GMT', 'userID': 4275}]\n",
      "\n",
      "\n",
      "[{'WhPerMile': 400, 'kWhRequested': 8.0, 'milesRequested': 20, 'minutesAvailable': 60, 'modifiedAt': 'Thu, 02 Jan 2020 13:57:17 GMT', 'paymentRequired': True, 'requestedDeparture': 'Thu, 02 Jan 2020 14:56:35 GMT', 'userID': 344}]\n",
      "\n",
      "\n",
      "[{'WhPerMile': 400, 'kWhRequested': 8.0, 'milesRequested': 20, 'minutesAvailable': 65, 'modifiedAt': 'Thu, 02 Jan 2020 14:00:03 GMT', 'paymentRequired': True, 'requestedDeparture': 'Thu, 02 Jan 2020 15:04:58 GMT', 'userID': 1117}, {'WhPerMile': 400, 'kWhRequested': 8.0, 'milesRequested': 20, 'minutesAvailable': 65, 'modifiedAt': 'Thu, 02 Jan 2020 14:00:19 GMT', 'paymentRequired': True, 'requestedDeparture': 'Thu, 02 Jan 2020 15:04:58 GMT', 'userID': 1117}]\n",
      "\n",
      "\n",
      "[{'WhPerMile': 400, 'kWhRequested': 16.0, 'milesRequested': 40, 'minutesAvailable': 504, 'modifiedAt': 'Thu, 02 Jan 2020 14:00:13 GMT', 'paymentRequired': True, 'requestedDeparture': 'Thu, 02 Jan 2020 22:24:01 GMT', 'userID': 334}]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(dfCharging['userInputs'].iloc[i])\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T16:57:08.153975Z",
     "start_time": "2023-12-05T16:57:08.051193Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "But another important point could be to check out if the amount of missing data in these columns is significantly high"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of missing data in userID: 25.97893152746426\n",
      "The percentage of missing data in userInputs: 25.97893152746426\n"
     ]
    }
   ],
   "source": [
    "#Calculate total amount of observations recorded\n",
    "total_observations_userID = len(dfCharging[\"userID\"])\n",
    "total_observations_userInputs = len(dfCharging[\"userInputs\"])\n",
    "\n",
    "#Calculate the amount of missing data\n",
    "total_missing_userID = dfCharging[\"userID\"].isnull().sum()\n",
    "total_missing_userInputs = dfCharging[\"userInputs\"].isnull().sum()\n",
    "\n",
    "#Calculate the percentage of missing values\n",
    "percentage_missing_userID = 100 * total_missing_userID / total_observations_userID\n",
    "percentage_missing_userInputs = 100 * total_missing_userInputs / total_observations_userInputs\n",
    "\n",
    "#Print the results\n",
    "print(\"The percentage of missing data in userID:\", percentage_missing_userID)\n",
    "print(\"The percentage of missing data in userInputs:\", percentage_missing_userInputs)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T16:57:08.170274Z",
     "start_time": "2023-12-05T16:57:08.061578Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dealing with Missing Data\n",
    "\n",
    "From the previous operations we see that almost a quarter of our data in these columns are missing. Therefore, we now have to decide how to deal with the missing data\n",
    "\n",
    "- Do we remove the rows with the missing data?\n",
    "\n",
    "- Do we keep the rows but ignore that these values are missing?\n",
    "\n",
    "- Do we consider ways to impute the missing values?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              connectionTime             disconnectTime  \\\n",
      "0  2020-01-02 13:08:54+00:00  2020-01-02 19:11:15+00:00   \n",
      "1  2020-01-02 13:36:50+00:00  2020-01-02 22:38:21+00:00   \n",
      "2  2020-01-02 13:56:35+00:00  2020-01-03 00:39:22+00:00   \n",
      "3  2020-01-02 13:59:58+00:00  2020-01-02 16:38:39+00:00   \n",
      "4  2020-01-02 14:00:01+00:00  2020-01-02 22:08:40+00:00   \n",
      "\n",
      "            doneChargingTime  \n",
      "0  2020-01-02 17:31:35+00:00  \n",
      "1  2020-01-02 20:18:05+00:00  \n",
      "2  2020-01-02 16:35:06+00:00  \n",
      "3  2020-01-02 15:18:45+00:00  \n",
      "4  2020-01-02 18:17:30+00:00  \n"
     ]
    }
   ],
   "source": [
    "print(dfCharging[['connectionTime', 'disconnectTime', 'doneChargingTime']].head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T16:57:08.170896Z",
     "start_time": "2023-12-05T16:57:08.090748Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision Point 1:\n",
    "Another column with a lot of missing data is the doneChargingTime column.\n",
    "\n",
    "But doneChargingTime could also be calculated using two other columns with zero missing values, for example by:\n",
    "\n",
    "*doneChargingTime = disconnectTime - connectionTime*\n",
    "\n",
    "But from line 11 we see that this is not the case, since a EV can still be connected to the system even though it has finished charging. So we should decide what to do:\n",
    " \n",
    "- Do we delete all columns in which there is nothing in doneChargingTime?\n",
    "\n",
    "- Do we calculate the median of how long it always took from connectionTime to doneChargingTime and then replace the median in the missing columns?\n",
    "\n",
    "'''\n",
    "dfCharging['connectionTime'] = pd.to_datetime(dfCharging['connectionTime'])\n",
    "dfCharging['disconnectTime'] = pd.to_datetime(dfCharging['disconnectTime'])\n",
    "dfCharging['doneChargingTime'] = pd.to_datetime(dfCharging['doneChargingTime'])\n",
    "\n",
    "dfCharging['calculatedDuration'] = dfCharging['doneChargingTime'] - dfCharging['connectionTime']\n",
    "\n",
    "median_duration = dfCharging['calculatedDuration'].median()\n",
    "\n",
    "dfCharging.loc[dfCharging['doneChargingTime'].isnull(), 'doneChargingTime'] = dfCharging['connectionTime'] + median_duration\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T16:57:08.379654Z",
     "start_time": "2023-12-05T16:57:08.099077Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      city            timestamp  temperature  cloud_cover  \\\n0  Burbank  2018-01-01 08:53:00          9.0         33.0   \n1  Burbank  2018-01-01 09:53:00          9.0         33.0   \n2  Burbank  2018-01-01 10:53:00          9.0         21.0   \n3  Burbank  2018-01-01 11:53:00          9.0         29.0   \n4  Burbank  2018-01-01 12:53:00          8.0         33.0   \n\n  cloud_cover_description  pressure  windspeed  precipitation  \\\n0                    Fair    991.75        9.0            0.0   \n1                    Fair    992.08        0.0            0.0   \n2                    Haze    992.08        0.0            0.0   \n3           Partly Cloudy    992.08        0.0            0.0   \n4                    Fair    992.08        0.0            0.0   \n\n   felt_temperature  \n0               8.0  \n1               9.0  \n2               9.0  \n3               9.0  \n4               8.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>city</th>\n      <th>timestamp</th>\n      <th>temperature</th>\n      <th>cloud_cover</th>\n      <th>cloud_cover_description</th>\n      <th>pressure</th>\n      <th>windspeed</th>\n      <th>precipitation</th>\n      <th>felt_temperature</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Burbank</td>\n      <td>2018-01-01 08:53:00</td>\n      <td>9.0</td>\n      <td>33.0</td>\n      <td>Fair</td>\n      <td>991.75</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Burbank</td>\n      <td>2018-01-01 09:53:00</td>\n      <td>9.0</td>\n      <td>33.0</td>\n      <td>Fair</td>\n      <td>992.08</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Burbank</td>\n      <td>2018-01-01 10:53:00</td>\n      <td>9.0</td>\n      <td>21.0</td>\n      <td>Haze</td>\n      <td>992.08</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Burbank</td>\n      <td>2018-01-01 11:53:00</td>\n      <td>9.0</td>\n      <td>29.0</td>\n      <td>Partly Cloudy</td>\n      <td>992.08</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Burbank</td>\n      <td>2018-01-01 12:53:00</td>\n      <td>8.0</td>\n      <td>33.0</td>\n      <td>Fair</td>\n      <td>992.08</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the weather data from burbank airport\n",
    "dfWeather = pd.read_csv(\"Data/weather_burbank_airport.csv\")\n",
    "dfWeather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T16:57:08.383498Z",
     "start_time": "2023-12-05T16:57:08.231056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29244 entries, 0 to 29243\n",
      "Data columns (total 9 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   city                     29244 non-null  object \n",
      " 1   timestamp                29244 non-null  object \n",
      " 2   temperature              29219 non-null  float64\n",
      " 3   cloud_cover              29224 non-null  float64\n",
      " 4   cloud_cover_description  29224 non-null  object \n",
      " 5   pressure                 29236 non-null  float64\n",
      " 6   windspeed                29158 non-null  float64\n",
      " 7   precipitation            29244 non-null  float64\n",
      " 8   felt_temperature         29218 non-null  float64\n",
      "dtypes: float64(6), object(3)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "dfWeather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T16:57:08.406556Z",
     "start_time": "2023-12-05T16:57:08.277450Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove duplicate rows\n",
    "dfWeather = dfWeather.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T16:57:08.407263Z",
     "start_time": "2023-12-05T16:57:08.304641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city                        0\n",
      "timestamp                   0\n",
      "temperature                25\n",
      "cloud_cover                20\n",
      "cloud_cover_description    20\n",
      "pressure                    8\n",
      "windspeed                  86\n",
      "precipitation               0\n",
      "felt_temperature           26\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(dfWeather.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The columns , ‘temperature’, ‘cloud_cover’, 'cloud_cover_description', 'pressure', 'windspeed' and ‘felt_temperature’ have a number of missing values.\n",
    "\n",
    "First we check if 'cloud_cover' and 'cloud_cover_description' columns match the userInputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines with missing \"cloud_cover\" and \"cloud_cover_description\": 20\n",
      "Percentage of compliance: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Check whether the lines with missing 'cloud_cover' also have missing 'cloud_cover_description'\n",
    "missing_userInputs = dfWeather['cloud_cover'].isnull()\n",
    "missing_userID = dfWeather['cloud_cover_description'].isnull()\n",
    "\n",
    "# Check that the missing values match\n",
    "matching_missing = dfWeather[missing_userInputs & missing_userID]\n",
    "\n",
    "# Output the number of matching lines\n",
    "print(f'Number of lines with missing \"cloud_cover\" and \"cloud_cover_description\": {len(matching_missing)}')\n",
    "\n",
    "# Calculate percentage of match\n",
    "total_missing_userInputs = len(dfWeather[missing_userInputs])\n",
    "if total_missing_userInputs > 0:\n",
    "    matching_percentage = (len(matching_missing) / total_missing_userInputs) * 100\n",
    "    print(f'Percentage of compliance: {matching_percentage:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T16:57:08.408270Z",
     "start_time": "2023-12-05T16:57:08.338979Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "At this point we could again check if the amount of missing data is significantly high"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of missing data in cloud_cover: 0.0683900971139379\n",
      "The percentage of missing data in cloud_cover_description: 0.0683900971139379\n"
     ]
    }
   ],
   "source": [
    "#Calculate total amount of observations recorded\n",
    "total_observations_cloud_cover = len(dfWeather[\"cloud_cover\"])\n",
    "total_observations_cloud_cover_description = len(dfWeather[\"cloud_cover_description\"])\n",
    "\n",
    "#Calculate the amount of missing data\n",
    "total_missing_cloud_cover = dfWeather[\"cloud_cover\"].isnull().sum()\n",
    "total_missing_cloud_cover_description = dfWeather[\"cloud_cover_description\"].isnull().sum()\n",
    "\n",
    "#Calculate the percentage of missing values\n",
    "percentage_missing_cloud_cover = 100 * total_missing_cloud_cover / total_observations_cloud_cover\n",
    "percentage_missing_cloud_cover_description = 100 * total_missing_cloud_cover_description / total_observations_cloud_cover_description\n",
    "\n",
    "#Print the results\n",
    "print(\"The percentage of missing data in cloud_cover:\", percentage_missing_cloud_cover)\n",
    "print(\"The percentage of missing data in cloud_cover_description:\", percentage_missing_cloud_cover_description)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T16:57:08.447459Z",
     "start_time": "2023-12-05T16:57:08.353150Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see that only 6% of our data is missing. We now could check the other columns with missing values to see how much of our data is missing there. We build a a for loop to do this faster. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values in temperature: 0.09%\n",
      "Percentage of missing values in pressure: 0.03%\n",
      "Percentage of missing values in windspeed: 0.29%\n",
      "Percentage of missing values in felt_temperature: 0.09%\n"
     ]
    }
   ],
   "source": [
    "# List of columns to check for missing values\n",
    "columns_to_check = [\"temperature\", \"pressure\", \"windspeed\", \"felt_temperature\"] \n",
    "\n",
    "for column in columns_to_check:\n",
    "    total_observations = len(dfWeather[column])\n",
    "    total_missing = dfWeather[column].isnull().sum()\n",
    "    percentage_missing = 100 * total_missing / total_observations\n",
    "    print(f\"Percentage of missing values in {column}: {percentage_missing:.2f}%\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T16:57:08.583919Z",
     "start_time": "2023-12-05T16:57:08.372650Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision Point 2:\n",
    "\n",
    "We now have to decide what to do with the missing data\n",
    "\n",
    "- Do we remove the rows with the missing data?\n",
    "\n",
    "- Do we keep the rows but ignore that these values are missing?\n",
    "\n",
    "- Do we consider ways to impute the missing values?\n",
    "\n",
    "For **weather data** we decide apply mean imputation for the following columns:\n",
    "\n",
    "- temperature\n",
    "- cloud cover\n",
    "- pressure\n",
    "- windspeed\n",
    "- felt temperature\n",
    "\n",
    "### Next Steps\n",
    "- have a look at the other missing lines\n",
    "- decide what to do with the missing data\n",
    "    - remove\n",
    "    - keep and ignore\n",
    "    - calculate\n",
    "- convert date and time information into a suitable format\n",
    "- merge the data (maybe over time stamp)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city                        0\n",
      "timestamp                   0\n",
      "temperature                 0\n",
      "cloud_cover                 0\n",
      "cloud_cover_description    20\n",
      "pressure                    0\n",
      "windspeed                   0\n",
      "precipitation               0\n",
      "felt_temperature            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Sort the DataFrame by timestamp\n",
    "dfWeather.sort_values(by='timestamp', inplace=True)\n",
    "\n",
    "# Function to impute missing values using the mean of neighboring values\n",
    "def impute_missing_values(column, window_size=5):\n",
    "    # Calculate the mean using a rolling window\n",
    "    # We have to use a window for the cases where some neighboring values are also missing.\n",
    "    return column.fillna(column.rolling(window=window_size, min_periods=1).mean())\n",
    "\n",
    "# Apply the imputation function to the specified columns\n",
    "columns_to_impute = ['temperature', 'cloud_cover', 'windspeed', 'pressure',\"felt_temperature\"]\n",
    "\n",
    "for column in columns_to_impute:\n",
    "    dfWeather[column] = impute_missing_values(dfWeather[column])\n",
    "\n",
    "# Verify the changes\n",
    "print(dfWeather.isnull().sum())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T16:57:08.635830Z",
     "start_time": "2023-12-05T16:57:08.393372Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city                       0\n",
      "timestamp                  0\n",
      "temperature                0\n",
      "cloud_cover                0\n",
      "cloud_cover_description    0\n",
      "pressure                   0\n",
      "windspeed                  0\n",
      "precipitation              0\n",
      "felt_temperature           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def fill_missing_cloud_cover_description(dfWeather):\n",
    "    dfWeather = dfWeather.sort_values(by='timestamp')  # Actually not needed because of the previous function\n",
    "\n",
    "    for index, row in dfWeather.iterrows():\n",
    "        if pd.isnull(row['cloud_cover_description']):\n",
    "            # Round the 'cloud_cover' value\n",
    "            rounded_cloud_cover = round(row['cloud_cover'])\n",
    "\n",
    "            # Try to find a match with the rounded 'cloud_cover'\n",
    "            matching_rows = dfWeather[(round(dfWeather['cloud_cover']) == rounded_cloud_cover) & (~pd.isnull(dfWeather['cloud_cover_description']))]\n",
    "\n",
    "            if not matching_rows.empty:\n",
    "                matching_description = matching_rows['cloud_cover_description'].values[0]\n",
    "                dfWeather.at[index, 'cloud_cover_description'] = matching_description\n",
    "            else:\n",
    "                # If no match is found, try to find a match for 'rounded_cloud_cover + 1'\n",
    "                next_matching_rows = dfWeather[(round(dfWeather['cloud_cover']) == rounded_cloud_cover + 1) & (~pd.isnull(dfWeather['cloud_cover_description']))]\n",
    "\n",
    "                if not next_matching_rows.empty:\n",
    "                    next_matching_description = next_matching_rows['cloud_cover_description'].values[0]\n",
    "                    dfWeather.at[index, 'cloud_cover_description'] = next_matching_description\n",
    "\n",
    "    return dfWeather\n",
    "\n",
    "dfWeather = fill_missing_cloud_cover_description(dfWeather)\n",
    "\n",
    "# Verify the changes\n",
    "print(dfWeather.isnull().sum())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T16:57:46.165031Z",
     "start_time": "2023-12-05T16:57:43.775652Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert the time columns to datetime objects\n",
    "dfCharging['connectionTime'] = pd.to_datetime(dfCharging['connectionTime'])\n",
    "dfCharging['disconnectTime'] = pd.to_datetime(dfCharging['disconnectTime'])\n",
    "dfCharging['doneChargingTime'] = pd.to_datetime(dfCharging['doneChargingTime'])\n",
    "\n",
    "# Compute the time differences\n",
    "dfCharging['disconnectDuration'] = dfCharging['disconnectTime'] - dfCharging['connectionTime']\n",
    "dfCharging['doneChargingDuration'] = dfCharging['doneChargingTime'] - dfCharging['connectionTime']\n",
    "dfCharging['doneToDisconnectDuration'] = dfCharging['disconnectTime'] - dfCharging['doneChargingTime']\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T16:57:09.055074Z",
     "start_time": "2023-12-05T16:57:09.046870Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Plot the duration\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(dfCharging['connectionTime'], dfCharging['disconnectDuration'].dt.total_seconds() / 3600,\n",
    "         marker='o', linestyle='-', color='b', label='Disconnect Duration')\n",
    "plt.plot(dfCharging['connectionTime'], dfCharging['doneChargingDuration'].dt.total_seconds() / 3600,\n",
    "         marker='o', linestyle='-', color='r', label='Done Charging Duration')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-05T16:57:09.052667Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.title('Duration of Charging Sessions')\n",
    "plt.xlabel('Connection Time')\n",
    "plt.ylabel('Duration (hours)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(dfCharging['connectionTime'], dfCharging['doneToDisconnectDuration'].dt.total_seconds() / 3600,\n",
    "         marker='o', linestyle='-', color='g', label='Done Charging to Disconnect Duration')\n",
    "\n",
    "plt.title('Duration of Charging Sessions')\n",
    "plt.xlabel('Connection Time')\n",
    "plt.ylabel('Duration (hours)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T16:57:09.055597Z",
     "start_time": "2023-12-05T16:57:09.055394Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-05T16:57:09.057269Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
