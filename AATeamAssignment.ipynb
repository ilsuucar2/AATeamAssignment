{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T16:37:53.521366Z",
     "end_time": "2023-11-17T16:37:53.607044Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import all necessary packages\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load the charging Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T16:37:53.534550Z",
     "end_time": "2023-11-17T16:37:54.055686Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0                        id             connectionTime  \\\n0           0  5e23b149f9af8b5fe4b973cf  2020-01-02 13:08:54+00:00   \n1           1  5e23b149f9af8b5fe4b973d0  2020-01-02 13:36:50+00:00   \n2           2  5e23b149f9af8b5fe4b973d1  2020-01-02 13:56:35+00:00   \n3           3  5e23b149f9af8b5fe4b973d2  2020-01-02 13:59:58+00:00   \n4           4  5e23b149f9af8b5fe4b973d3  2020-01-02 14:00:01+00:00   \n\n              disconnectTime           doneChargingTime  kWhDelivered  \\\n0  2020-01-02 19:11:15+00:00  2020-01-02 17:31:35+00:00        25.016   \n1  2020-01-02 22:38:21+00:00  2020-01-02 20:18:05+00:00        33.097   \n2  2020-01-03 00:39:22+00:00  2020-01-02 16:35:06+00:00         6.521   \n3  2020-01-02 16:38:39+00:00  2020-01-02 15:18:45+00:00         2.355   \n4  2020-01-02 22:08:40+00:00  2020-01-02 18:17:30+00:00        13.375   \n\n                                sessionID  siteID  spaceID    stationID  \\\n0  1_1_179_810_2020-01-02 13:08:53.870034       1  AG-3F30  1-1-179-810   \n1  1_1_193_825_2020-01-02 13:36:49.599853       1  AG-1F01  1-1-193-825   \n2  1_1_193_829_2020-01-02 13:56:35.214993       1  AG-1F03  1-1-193-829   \n3  1_1_193_820_2020-01-02 13:59:58.309319       1  AG-1F04  1-1-193-820   \n4  1_1_193_819_2020-01-02 14:00:00.779967       1  AG-1F06  1-1-193-819   \n\n              timezone  userID  \\\n0  America/Los_Angeles   194.0   \n1  America/Los_Angeles  4275.0   \n2  America/Los_Angeles   344.0   \n3  America/Los_Angeles  1117.0   \n4  America/Los_Angeles   334.0   \n\n                                          userInputs  \n0  [{'WhPerMile': 250, 'kWhRequested': 25.0, 'mil...  \n1  [{'WhPerMile': 280, 'kWhRequested': 70.0, 'mil...  \n2  [{'WhPerMile': 400, 'kWhRequested': 8.0, 'mile...  \n3  [{'WhPerMile': 400, 'kWhRequested': 8.0, 'mile...  \n4  [{'WhPerMile': 400, 'kWhRequested': 16.0, 'mil...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>connectionTime</th>\n      <th>disconnectTime</th>\n      <th>doneChargingTime</th>\n      <th>kWhDelivered</th>\n      <th>sessionID</th>\n      <th>siteID</th>\n      <th>spaceID</th>\n      <th>stationID</th>\n      <th>timezone</th>\n      <th>userID</th>\n      <th>userInputs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>5e23b149f9af8b5fe4b973cf</td>\n      <td>2020-01-02 13:08:54+00:00</td>\n      <td>2020-01-02 19:11:15+00:00</td>\n      <td>2020-01-02 17:31:35+00:00</td>\n      <td>25.016</td>\n      <td>1_1_179_810_2020-01-02 13:08:53.870034</td>\n      <td>1</td>\n      <td>AG-3F30</td>\n      <td>1-1-179-810</td>\n      <td>America/Los_Angeles</td>\n      <td>194.0</td>\n      <td>[{'WhPerMile': 250, 'kWhRequested': 25.0, 'mil...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>5e23b149f9af8b5fe4b973d0</td>\n      <td>2020-01-02 13:36:50+00:00</td>\n      <td>2020-01-02 22:38:21+00:00</td>\n      <td>2020-01-02 20:18:05+00:00</td>\n      <td>33.097</td>\n      <td>1_1_193_825_2020-01-02 13:36:49.599853</td>\n      <td>1</td>\n      <td>AG-1F01</td>\n      <td>1-1-193-825</td>\n      <td>America/Los_Angeles</td>\n      <td>4275.0</td>\n      <td>[{'WhPerMile': 280, 'kWhRequested': 70.0, 'mil...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5e23b149f9af8b5fe4b973d1</td>\n      <td>2020-01-02 13:56:35+00:00</td>\n      <td>2020-01-03 00:39:22+00:00</td>\n      <td>2020-01-02 16:35:06+00:00</td>\n      <td>6.521</td>\n      <td>1_1_193_829_2020-01-02 13:56:35.214993</td>\n      <td>1</td>\n      <td>AG-1F03</td>\n      <td>1-1-193-829</td>\n      <td>America/Los_Angeles</td>\n      <td>344.0</td>\n      <td>[{'WhPerMile': 400, 'kWhRequested': 8.0, 'mile...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>5e23b149f9af8b5fe4b973d2</td>\n      <td>2020-01-02 13:59:58+00:00</td>\n      <td>2020-01-02 16:38:39+00:00</td>\n      <td>2020-01-02 15:18:45+00:00</td>\n      <td>2.355</td>\n      <td>1_1_193_820_2020-01-02 13:59:58.309319</td>\n      <td>1</td>\n      <td>AG-1F04</td>\n      <td>1-1-193-820</td>\n      <td>America/Los_Angeles</td>\n      <td>1117.0</td>\n      <td>[{'WhPerMile': 400, 'kWhRequested': 8.0, 'mile...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>5e23b149f9af8b5fe4b973d3</td>\n      <td>2020-01-02 14:00:01+00:00</td>\n      <td>2020-01-02 22:08:40+00:00</td>\n      <td>2020-01-02 18:17:30+00:00</td>\n      <td>13.375</td>\n      <td>1_1_193_819_2020-01-02 14:00:00.779967</td>\n      <td>1</td>\n      <td>AG-1F06</td>\n      <td>1-1-193-819</td>\n      <td>America/Los_Angeles</td>\n      <td>334.0</td>\n      <td>[{'WhPerMile': 400, 'kWhRequested': 16.0, 'mil...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset\n",
    "dfCharging = pd.read_csv(\"Data/charging_sessions.csv\")\n",
    "dfCharging.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T16:37:54.058479Z",
     "end_time": "2023-11-17T16:37:54.127391Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 66450 entries, 0 to 66449\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Unnamed: 0        66450 non-null  int64  \n",
      " 1   id                66450 non-null  object \n",
      " 2   connectionTime    66450 non-null  object \n",
      " 3   disconnectTime    66450 non-null  object \n",
      " 4   doneChargingTime  62362 non-null  object \n",
      " 5   kWhDelivered      66450 non-null  float64\n",
      " 6   sessionID         66450 non-null  object \n",
      " 7   siteID            66450 non-null  int64  \n",
      " 8   spaceID           66450 non-null  object \n",
      " 9   stationID         66450 non-null  object \n",
      " 10  timezone          66450 non-null  object \n",
      " 11  userID            49187 non-null  float64\n",
      " 12  userInputs        49187 non-null  object \n",
      "dtypes: float64(2), int64(2), object(9)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "dfCharging.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T16:37:54.086369Z",
     "end_time": "2023-11-17T16:37:54.202219Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove duplicate rows\n",
    "dfCharging = dfCharging.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0              0\n",
      "id                      0\n",
      "connectionTime          0\n",
      "disconnectTime          0\n",
      "doneChargingTime     4088\n",
      "kWhDelivered            0\n",
      "sessionID               0\n",
      "siteID                  0\n",
      "spaceID                 0\n",
      "stationID               0\n",
      "timezone                0\n",
      "userID              17263\n",
      "userInputs          17263\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(dfCharging.isnull().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-17T16:37:54.203399Z",
     "end_time": "2023-11-17T16:37:54.243203Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The columns , 'userID', 'userInputs' and 'doneChargingTime' have a considerable number of missing values.\n",
    "First I want to check 'whether' the 'userID' lines match the userInputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines with missing \"userID\" and \"userIputs\": 17263\n",
      "Percentage of compliance: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Check whether the lines with missing 'userInputs' also have missing 'userID'\n",
    "missing_userInputs = dfCharging['userInputs'].isnull()\n",
    "missing_userID = dfCharging['userID'].isnull()\n",
    "\n",
    "# Check that the missing values match\n",
    "matching_missing = dfCharging[missing_userInputs & missing_userID]\n",
    "\n",
    "# Output the number of matching lines\n",
    "print(f'Number of lines with missing \"userID\" and \"userIputs\": {len(matching_missing)}')\n",
    "\n",
    "# Calculate percentage of match\n",
    "total_missing_userInputs = len(dfCharging[missing_userInputs])\n",
    "if total_missing_userInputs > 0:\n",
    "    matching_percentage = (len(matching_missing) / total_missing_userInputs) * 100\n",
    "    print(f'Percentage of compliance: {matching_percentage:.2f}%')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-17T16:37:54.233452Z",
     "end_time": "2023-11-17T16:37:54.250488Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "0     194.0\n1    4275.0\n2     344.0\n3    1117.0\n4     334.0\nName: userID, dtype: float64"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCharging['userID'].head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-17T16:37:54.252839Z",
     "end_time": "2023-11-17T16:37:54.257283Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "0    [{'WhPerMile': 250, 'kWhRequested': 25.0, 'mil...\n1    [{'WhPerMile': 280, 'kWhRequested': 70.0, 'mil...\n2    [{'WhPerMile': 400, 'kWhRequested': 8.0, 'mile...\n3    [{'WhPerMile': 400, 'kWhRequested': 8.0, 'mile...\n4    [{'WhPerMile': 400, 'kWhRequested': 16.0, 'mil...\nName: userInputs, dtype: object"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCharging['userInputs'].head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-17T16:37:54.261266Z",
     "end_time": "2023-11-17T16:37:54.297978Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'WhPerMile': 250, 'kWhRequested': 25.0, 'milesRequested': 100, 'minutesAvailable': 463, 'modifiedAt': 'Thu, 02 Jan 2020 13:09:39 GMT', 'paymentRequired': True, 'requestedDeparture': 'Thu, 02 Jan 2020 20:51:54 GMT', 'userID': 194}]\n",
      "\n",
      "\n",
      "[{'WhPerMile': 280, 'kWhRequested': 70.0, 'milesRequested': 250, 'minutesAvailable': 595, 'modifiedAt': 'Thu, 02 Jan 2020 13:37:11 GMT', 'paymentRequired': True, 'requestedDeparture': 'Thu, 02 Jan 2020 23:31:50 GMT', 'userID': 4275}]\n",
      "\n",
      "\n",
      "[{'WhPerMile': 400, 'kWhRequested': 8.0, 'milesRequested': 20, 'minutesAvailable': 60, 'modifiedAt': 'Thu, 02 Jan 2020 13:57:17 GMT', 'paymentRequired': True, 'requestedDeparture': 'Thu, 02 Jan 2020 14:56:35 GMT', 'userID': 344}]\n",
      "\n",
      "\n",
      "[{'WhPerMile': 400, 'kWhRequested': 8.0, 'milesRequested': 20, 'minutesAvailable': 65, 'modifiedAt': 'Thu, 02 Jan 2020 14:00:03 GMT', 'paymentRequired': True, 'requestedDeparture': 'Thu, 02 Jan 2020 15:04:58 GMT', 'userID': 1117}, {'WhPerMile': 400, 'kWhRequested': 8.0, 'milesRequested': 20, 'minutesAvailable': 65, 'modifiedAt': 'Thu, 02 Jan 2020 14:00:19 GMT', 'paymentRequired': True, 'requestedDeparture': 'Thu, 02 Jan 2020 15:04:58 GMT', 'userID': 1117}]\n",
      "\n",
      "\n",
      "[{'WhPerMile': 400, 'kWhRequested': 16.0, 'milesRequested': 40, 'minutesAvailable': 504, 'modifiedAt': 'Thu, 02 Jan 2020 14:00:13 GMT', 'paymentRequired': True, 'requestedDeparture': 'Thu, 02 Jan 2020 22:24:01 GMT', 'userID': 334}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(dfCharging['userInputs'].iloc[i])\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-17T16:37:54.267830Z",
     "end_time": "2023-11-17T16:37:54.304459Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision Needed\n",
    "\n",
    "We now have to decide what to do with the missing data\n",
    "\n",
    "- Do we remove the rows with the missing data?\n",
    "\n",
    "- Do we keep the rows but ignore that these values are missing?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              connectionTime             disconnectTime  \\\n",
      "0  2020-01-02 13:08:54+00:00  2020-01-02 19:11:15+00:00   \n",
      "1  2020-01-02 13:36:50+00:00  2020-01-02 22:38:21+00:00   \n",
      "2  2020-01-02 13:56:35+00:00  2020-01-03 00:39:22+00:00   \n",
      "3  2020-01-02 13:59:58+00:00  2020-01-02 16:38:39+00:00   \n",
      "4  2020-01-02 14:00:01+00:00  2020-01-02 22:08:40+00:00   \n",
      "\n",
      "            doneChargingTime  \n",
      "0  2020-01-02 17:31:35+00:00  \n",
      "1  2020-01-02 20:18:05+00:00  \n",
      "2  2020-01-02 16:35:06+00:00  \n",
      "3  2020-01-02 15:18:45+00:00  \n",
      "4  2020-01-02 18:17:30+00:00  \n"
     ]
    }
   ],
   "source": [
    "print(dfCharging[['connectionTime', 'disconnectTime', 'doneChargingTime']].head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-17T16:37:54.280172Z",
     "end_time": "2023-11-17T16:37:54.305089Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision Needed\n",
    "Here we have to decide what we want to do,\n",
    "\n",
    "I wanted to see if doneChargingTime could also be calculated, for example by\n",
    "\n",
    "doneChargingTime = disconnectTime - connectionTime\n",
    "\n",
    "But here we can see that this is not the case, so we should decide what to do, do we delete all columns in which there is nothing in doneChargingTime or should we calculate the median of how long it always took from connectionTime to doneChargingTime and then replace the median in the missing columns?\n",
    "\n",
    "'''\n",
    "dfCharging['connectionTime'] = pd.to_datetime(dfCharging['connectionTime'])\n",
    "dfCharging['disconnectTime'] = pd.to_datetime(dfCharging['disconnectTime'])\n",
    "dfCharging['doneChargingTime'] = pd.to_datetime(dfCharging['doneChargingTime'])\n",
    "\n",
    "dfCharging['calculatedDuration'] = dfCharging['doneChargingTime'] - dfCharging['connectionTime']\n",
    "\n",
    "median_duration = dfCharging['calculatedDuration'].median()\n",
    "\n",
    "dfCharging.loc[dfCharging['doneChargingTime'].isnull(), 'doneChargingTime'] = dfCharging['connectionTime'] + median_duration\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load the Weather Data for Burbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T16:37:54.286244Z",
     "end_time": "2023-11-17T16:37:54.365760Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      city            timestamp  temperature  cloud_cover  \\\n0  Burbank  2018-01-01 08:53:00          9.0         33.0   \n1  Burbank  2018-01-01 09:53:00          9.0         33.0   \n2  Burbank  2018-01-01 10:53:00          9.0         21.0   \n3  Burbank  2018-01-01 11:53:00          9.0         29.0   \n4  Burbank  2018-01-01 12:53:00          8.0         33.0   \n\n  cloud_cover_description  pressure  windspeed  precipitation  \\\n0                    Fair    991.75        9.0            0.0   \n1                    Fair    992.08        0.0            0.0   \n2                    Haze    992.08        0.0            0.0   \n3           Partly Cloudy    992.08        0.0            0.0   \n4                    Fair    992.08        0.0            0.0   \n\n   felt_temperature  \n0               8.0  \n1               9.0  \n2               9.0  \n3               9.0  \n4               8.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>city</th>\n      <th>timestamp</th>\n      <th>temperature</th>\n      <th>cloud_cover</th>\n      <th>cloud_cover_description</th>\n      <th>pressure</th>\n      <th>windspeed</th>\n      <th>precipitation</th>\n      <th>felt_temperature</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Burbank</td>\n      <td>2018-01-01 08:53:00</td>\n      <td>9.0</td>\n      <td>33.0</td>\n      <td>Fair</td>\n      <td>991.75</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Burbank</td>\n      <td>2018-01-01 09:53:00</td>\n      <td>9.0</td>\n      <td>33.0</td>\n      <td>Fair</td>\n      <td>992.08</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Burbank</td>\n      <td>2018-01-01 10:53:00</td>\n      <td>9.0</td>\n      <td>21.0</td>\n      <td>Haze</td>\n      <td>992.08</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Burbank</td>\n      <td>2018-01-01 11:53:00</td>\n      <td>9.0</td>\n      <td>29.0</td>\n      <td>Partly Cloudy</td>\n      <td>992.08</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Burbank</td>\n      <td>2018-01-01 12:53:00</td>\n      <td>8.0</td>\n      <td>33.0</td>\n      <td>Fair</td>\n      <td>992.08</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfWeather = pd.read_csv(\"Data/weather_burbank_airport.csv\")\n",
    "dfWeather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T16:37:54.344646Z",
     "end_time": "2023-11-17T16:37:54.366359Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29244 entries, 0 to 29243\n",
      "Data columns (total 9 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   city                     29244 non-null  object \n",
      " 1   timestamp                29244 non-null  object \n",
      " 2   temperature              29219 non-null  float64\n",
      " 3   cloud_cover              29224 non-null  float64\n",
      " 4   cloud_cover_description  29224 non-null  object \n",
      " 5   pressure                 29236 non-null  float64\n",
      " 6   windspeed                29158 non-null  float64\n",
      " 7   precipitation            29244 non-null  float64\n",
      " 8   felt_temperature         29218 non-null  float64\n",
      "dtypes: float64(6), object(3)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "dfWeather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T16:37:54.354563Z",
     "end_time": "2023-11-17T16:37:54.397054Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove duplicate rows\n",
    "dfWeather = dfWeather.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-17T16:37:54.374165Z",
     "end_time": "2023-11-17T16:37:54.413282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city                        0\n",
      "timestamp                   0\n",
      "temperature                25\n",
      "cloud_cover                20\n",
      "cloud_cover_description    20\n",
      "pressure                    8\n",
      "windspeed                  86\n",
      "precipitation               0\n",
      "felt_temperature           26\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(dfWeather.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The columns , ‘temperature’, ‘cloud_cover’, 'cloud_cover_description', 'pressure', 'windspeed' and ‘felt_temperature’ have a number of missing values.\n",
    "First I want to check 'cloud_cover' the 'cloud_cover_description' lines match the userInputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines with missing \"cloud_cover\" and \"cloud_cover_description\": 20\n",
      "Percentage of compliance: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Check whether the lines with missing 'cloud_cover' also have missing 'cloud_cover_description'\n",
    "missing_userInputs = dfWeather['cloud_cover'].isnull()\n",
    "missing_userID = dfWeather['cloud_cover_description'].isnull()\n",
    "\n",
    "# Check that the missing values match\n",
    "matching_missing = dfWeather[missing_userInputs & missing_userID]\n",
    "\n",
    "# Output the number of matching lines\n",
    "print(f'Number of lines with missing \"cloud_cover\" and \"cloud_cover_description\": {len(matching_missing)}')\n",
    "\n",
    "# Calculate percentage of match\n",
    "total_missing_userInputs = len(dfWeather[missing_userInputs])\n",
    "if total_missing_userInputs > 0:\n",
    "    matching_percentage = (len(matching_missing) / total_missing_userInputs) * 100\n",
    "    print(f'Percentage of compliance: {matching_percentage:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-17T16:37:54.393848Z",
     "end_time": "2023-11-17T16:37:54.413654Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision Needed\n",
    "\n",
    "We now have to decide what to do with the missing data\n",
    "\n",
    "- Do we remove the rows with the missing data?\n",
    "\n",
    "- Do we keep the rows but ignore that these values are missing?\n",
    "\n",
    "### Next Steps\n",
    "- have a look at the other missing lines\n",
    "- decide what to do with the missing data\n",
    "    - remove\n",
    "    - keep and ignore\n",
    "    - calculate\n",
    "- convert date and time information into a suitable format\n",
    "- merge the data (maybe over time stamp)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
